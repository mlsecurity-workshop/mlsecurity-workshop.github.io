[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Adversarial Threats on Real Life Learning Systems",
    "section": "",
    "text": "Important Information\n\nDate: September 17th, 2025\n\nTime: 9h00 - 17h30\n\nLocation: Esclangon building, first floor, salle de séminaire, Campus Pierre et Marie Curie, 4 place Jussieu, 75005 Paris\nLanguage: English\nRegistration: Mandatory (Limited places)\nCost: Free\n\n\n\n\nThis workshop focuses on adversarial and backdoor attacks targeting real-life machine learning systems. We will explore vulnerabilities in deployed learning systems, examine attack vectors in practical scenarios, and discuss defense mechanisms for robust ML deployment. The workshop is inspired by research from the KINAITICS project, which investigates kinematic indicators for adversarial behavior detection in AI systems. The event brings together researchers, academics, and industry professionals to discuss cutting-edge developments in adversarial machine learning, security implications, and mitigation strategies for production environments.\n\n\n\nRafaël Pinot (Sorbonne University) and Cédric Gouy-Pailler (CEA)"
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "Adversarial Threats on Real Life Learning Systems",
    "section": "",
    "text": "Important Information\n\nDate: September 17th, 2025\n\nTime: 9h00 - 17h30\n\nLocation: Esclangon building, first floor, salle de séminaire, Campus Pierre et Marie Curie, 4 place Jussieu, 75005 Paris\nLanguage: English\nRegistration: Mandatory (Limited places)\nCost: Free\n\n\n\n\nThis workshop focuses on adversarial and backdoor attacks targeting real-life machine learning systems. We will explore vulnerabilities in deployed learning systems, examine attack vectors in practical scenarios, and discuss defense mechanisms for robust ML deployment. The workshop is inspired by research from the KINAITICS project, which investigates kinematic indicators for adversarial behavior detection in AI systems. The event brings together researchers, academics, and industry professionals to discuss cutting-edge developments in adversarial machine learning, security implications, and mitigation strategies for production environments.\n\n\n\nRafaël Pinot (Sorbonne University) and Cédric Gouy-Pailler (CEA)"
  },
  {
    "objectID": "index.html#program",
    "href": "index.html#program",
    "title": "Adversarial Threats on Real Life Learning Systems",
    "section": "Program",
    "text": "Program\n\nWorkshop Agenda\nSeptember 17th, 2025\n\nprogram\n\n\n\n\n\n\n\nTime\nSession\nSpeaker\n\n\n\n\n9h00 - 9h25\nRegistration & Welcome Coffee\n\n\n\n9h25 - 9h30\nOpening Remarks\nRafaël PINOT (Sorbonne University) & Cédric GOUY-PAILLER (CEA)\n\n\n9h30 - 10h30\nKeynote 1: Backdoors in Artificial Intelligence: Stealth Weapon or Structural Weakness? [Slides]\nKassem KALLAS (INSERM, IMT Atlantique)\n\n\n10h30 - 11h00\nCoffee Break\n\n\n\n11h00 - 12h00\nSession 1:\n\n\n\n\nDeceiving Defect Detection: Backdoor Attacks Against SHM models in the Physical World\nAurélien MAYOUE (CEA)\n\n\n\nVerifiable Federated Learning with Incremental Zero-Knowledge Proofs\nAleksei KORNEEV (Université de Lille, INRIA)\n\n\n12h00 - 13h30\nLunch Break\n\n\n\n13h30 - 14h30\nKeynote 2: Adversarial attacks and mitigations\nBenjamin NEGREVERGNE (PSL Paris-Dauphine University)\n\n\n14h30 - 16h00\nSession 2:\n\n\n\n\nTopological safeguard for evasion attack interpreting the neural networks’ behavior\nXabier ECHEBERRIA BARRIO (VicomTech, Spain)\n\n\n\nFrom Attacks to Answers: Counterfactuals at the Intersection of Robustness and Explainability in AI\nDavy PREUVENEERS (KU Leuven, Belgium)\n\n\n\nUnveiling the Role of Randomization in Multiclass Adversarial Classification: Insights from Graph Theory\nMatteo SAMMUT (Université Paris-Dauphine)\n\n\n16h00 - 16h30\nCoffee Break\n\n\n\n16h30 - 17h30\nSession 3:\n\n\n\n\nTowards Byzantine-Resilient Dynamic Gossip Learning [Slides]\nSonia BEN MOKHTAR (LIRIS, CNRS)\n\n\n\nUnified Breakdown Analysis for Byzantine Robust Gossip [Slides]\nRenaud GAUCHER (Ecole Polytechnique)\n\n\n17h30\nClosing Remarks\nOrganizers\n\n\n\nProgram subject to modifications\n\n\nKeynote Speakers\n\n\n\n  \n    \n    \n      Dr. Kassem KALLAS\n      INSERM, IMT Atlantique\n      Senior Scientist, HDR\n    \n  \n  Keynote 1: Backdoors in Artificial Intelligence: Stealth Weapon or Structural Weakness?\n  Abstract: Backdoor attacks represent a stealthy yet serious threat to the \n  integrity of AI systems, especially in black-box image classification settings. This talk will begin with a general introduction to backdoor threats, \n  outlining the attack assumptions, threat models, and real-world implications. It will then present a series of concrete attack and defense strategies \n  developed in recent research. The keynote will conclude with a forward-looking perspective on either the use of watermarking for model ownership \n  verification or the unique challenges posed by backdoor attacks in federated learning.\n\n\n\n\n  \n    \n    \n      Dr. Benjamin NEGREVERGNE\n      LAMSADE, PSL-Paris Dauphine University\n      Associate Professor\n    \n  \n  Keynote 2: Adversarial attacks and mitigations\n  Abstract: Adversarial machine learning no longer centers on imperceptible pixel tweaks. \n  As foundation models become multimodal and instruction-tuned, the attack surface shifts to safety \n  alignment itself and to the prompts that govern multi-turn reasoning. This talk frames these trends—adversarial \n  alignment and prompt-level manipulation—using recent studies on large language and vision-language systems as \n  touchstones, and outlines why future defenses must address both model internals and their interactive context.\n\n\n\n\n\n\nOnline Registration Form (Attendance only)\n\nRegistration Form\n\n  \n    \n      Nom (Last Name) *\n      \n    \n    \n      Prénom (First Name) *\n      \n    \n  \n  \n  \n    \n      Email *\n      \n    \n  \n  \n  \n    Affiliation/Institution *\n    \n  \n  \n  \n    \n      Position *\n      \n        -- Select Position --\n        Professor\n        Researcher\n        Post-doctoral Researcher\n        PhD Student\n        Master Student\n        Industry Professional\n        Other\n      \n    \n    \n      Country\n      \n    \n  \n  \n  \n  \n    Participation Type *\n    \n      \n        \n        Attendance only\n      \n\n    \n  \n  \n  \n  \n    \n      Presentation Title\n      \n    \n\n    \n    \n      Abstract (max 300 words)\n      \n    \n    \n    \n      Published Paper Reference (if applicable)\n      \n      \n        Note: Proposals based on published papers will be given priority for talk slots.\n      \n    \n  \n  \n  \n    \n    I consent to the processing of my personal data for this event *"
  },
  {
    "objectID": "index.html#practical",
    "href": "index.html#practical",
    "title": "Adversarial Threats on Real Life Learning Systems",
    "section": "Practical Information",
    "text": "Practical Information\n\nVenue Details\n\nEsclangon Building\nCampus Pierre et Marie Curie\n4 place Jussieu, 75005 Paris\nFrance\nCapacity: 40 participants\n\n\n\nGetting There\nLocation on Maps: - Google Maps - OpenStreetMap\nBy Public Transport: - Metro: Line 7, 10 (Jussieu station) - Direct access - RER: Line C (Saint-Michel Notre-Dame) - 5 min walk - Bus: Lines 63, 67, 86, 87 (Jussieu stop)\nBy Car: - Limited parking in the area - Nearby parking: Parking Maubert (5 min walk) - Parking locations on Google Maps"
  },
  {
    "objectID": "index.html#sponsors",
    "href": "index.html#sponsors",
    "title": "Adversarial Threats on Real Life Learning Systems",
    "section": "Sponsors & Partners",
    "text": "Sponsors & Partners\nWe thank our sponsors and partners for their support:\n\n  \n  \n  \n  \n  \n  \n\n\nThe workshop is supported by the Responsible AI Team.\nThe KINAITICS project is funded under Horizon Europe Grant Agreement n°101070176. Views and opinions expressed are however those of the author(s) only and do not necessarily reflect those of the European Union. Neither the European Union nor the granting authority can be held responsible for them."
  }
]